{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0550b08f-8e0c-42b4-806b-9e9e4314410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Label               Value  \\\n",
      "0              کد آگهی               25923   \n",
      "1                منطقه           کوی فیروز   \n",
      "2                متراژ                 175   \n",
      "3              قیمت کل  ۵٬۹۵۰٬۰۰۰٬۰۰۰تومان   \n",
      "4                 طبقه                   2   \n",
      "5           تعداد اتاق                   3   \n",
      "6             کل طبقات                   6   \n",
      "7   تعداد واحد در طبقه                   1   \n",
      "8             سال ساخت                1401   \n",
      "9               موقعیت               جنوبی   \n",
      "10            نوع ساخت            شخصی ساز   \n",
      "11             نوع سند             شش دانگ   \n",
      "12             کد آگهی               31208   \n",
      "13               منطقه        ولیعصر جنوبی   \n",
      "14               متراژ                 210   \n",
      "15             قیمت کل  ۹٬۴۰۰٬۰۰۰٬۰۰۰تومان   \n",
      "16                طبقه                   6   \n",
      "17          تعداد اتاق                   3   \n",
      "18            کل طبقات                   6   \n",
      "19  تعداد واحد در طبقه                   1   \n",
      "20            سال ساخت                1402   \n",
      "21              موقعیت               جنوبی   \n",
      "22            نوع ساخت            شخصی ساز   \n",
      "23             نوع سند        در دست اقدام   \n",
      "\n",
      "                                    URL  \n",
      "0   https://www.melketabriz.com/p/25923  \n",
      "1   https://www.melketabriz.com/p/25923  \n",
      "2   https://www.melketabriz.com/p/25923  \n",
      "3   https://www.melketabriz.com/p/25923  \n",
      "4   https://www.melketabriz.com/p/25923  \n",
      "5   https://www.melketabriz.com/p/25923  \n",
      "6   https://www.melketabriz.com/p/25923  \n",
      "7   https://www.melketabriz.com/p/25923  \n",
      "8   https://www.melketabriz.com/p/25923  \n",
      "9   https://www.melketabriz.com/p/25923  \n",
      "10  https://www.melketabriz.com/p/25923  \n",
      "11  https://www.melketabriz.com/p/25923  \n",
      "12  https://www.melketabriz.com/p/31208  \n",
      "13  https://www.melketabriz.com/p/31208  \n",
      "14  https://www.melketabriz.com/p/31208  \n",
      "15  https://www.melketabriz.com/p/31208  \n",
      "16  https://www.melketabriz.com/p/31208  \n",
      "17  https://www.melketabriz.com/p/31208  \n",
      "18  https://www.melketabriz.com/p/31208  \n",
      "19  https://www.melketabriz.com/p/31208  \n",
      "20  https://www.melketabriz.com/p/31208  \n",
      "21  https://www.melketabriz.com/p/31208  \n",
      "22  https://www.melketabriz.com/p/31208  \n",
      "23  https://www.melketabriz.com/p/31208  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract data from a single URL\n",
    "def extract_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    labels = [\"کد آگهی\",\n",
    "          \"منطقه\",\n",
    "          \"محله\",\n",
    "          \"متراژ\",\n",
    "          \"قیمت کل\", \n",
    "          \"طبقه\",\n",
    "          \"تعداد اتاق\",\n",
    "          \"سال ساخت\",\n",
    "          \"نوع سند\"\n",
    "          ,\"کل طبقات\", \n",
    "          \"تعداد واحد در طبقه\",\n",
    "          \"موقعیت\",\n",
    "          \"نوع ساخت\",  \n",
    "          \"زمان تحویل\"\n",
    "          ]\n",
    "    \n",
    "    label_elements = soup.find_all(class_=\"label-infmlk\")\n",
    "    text_elements = soup.find_all(class_=\"text-infmlk\")\n",
    "    \n",
    "    data = {\n",
    "        \"Label\": [],\n",
    "        \"Value\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(label_elements)):\n",
    "        label_text = label_elements[i].find('div').get_text(strip=True)\n",
    "        if label_text in labels:\n",
    "            text = text_elements[i].find('div').get_text(strip=True)\n",
    "            data[\"Label\"].append(label_text)\n",
    "            data[\"Value\"].append(text)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    'https://www.melketabriz.com/p/25923', \n",
    "    'https://www.melketabriz.com/p/31208',\n",
    "    # Add more URLs as needed\n",
    "]\n",
    "\n",
    "# List to hold all DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through URLs and extract data\n",
    "for url in urls:\n",
    "    df = extract_data(url)\n",
    "    df['URL'] = url  # Add URL column to distinguish data from different pages\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat(dfs, ignore_index=True , axis= 1)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file with UTF-8 encoding\n",
    "combined_df.to_csv('combined_property_info.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Print the combined DataFrame to verify\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "497aa871-5eac-441f-bc0b-3038731ffb39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Concatenate all DataFrames\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m , axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Save the combined DataFrame to a CSV file with UTF-8 encoding\u001b[39;00m\n\u001b[0;32m     28\u001b[0m combined_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_property_info.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Eyvazlou\\anaconda3\\envs\\myML\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    381\u001b[0m     objs,\n\u001b[0;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    383\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    384\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    385\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    386\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    387\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    388\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    389\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    391\u001b[0m )\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mD:\\Eyvazlou\\anaconda3\\envs\\myML\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:446\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n\u001b[0;32m    447\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Eyvazlou\\anaconda3\\envs\\myML\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:487\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[1;34m(self, objs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    483\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    484\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         )\n\u001b[1;32m--> 487\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    489\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# List to hold all DataFrames\n",
    "dfs = [\"کد آگهی\",\n",
    "          \"منطقه\",\n",
    "          \"محله\",\n",
    "          \"متراژ\",\n",
    "          \"قیمت کل\", \n",
    "          \"طبقه\",\n",
    "          \"تعداد اتاق\",\n",
    "          \"سال ساخت\",\n",
    "          \"نوع سند\"\n",
    "          ,\"کل طبقات\", \n",
    "          \"تعداد واحد در طبقه\",\n",
    "          \"موقعیت\",\n",
    "          \"نوع ساخت\",  \n",
    "          \"زمان تحویل\"\n",
    "          ]\n",
    "\n",
    "# Loop through URLs and extract data\n",
    "for url in urls:\n",
    "    df = extract_data(url)\n",
    "    #df['URL'] = url  # Add URL column to distinguish data from different pages\n",
    "    dfs.append(df[[\"Value\"]])\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat(dfs, ignore_index=True , axis= 1)#.fillna('')\n",
    "\n",
    "# Save the combined DataFrame to a CSV file with UTF-8 encoding\n",
    "combined_df.to_csv('combined_property_info.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Print the combined DataFrame to verify\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0564272-39fd-4434-ba27-3d6348493312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3fc5eb6-6f4c-4dcb-b0e4-eeb7f28116d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                کد آگهی\n",
      "1                  منطقه\n",
      "2                  متراژ\n",
      "3                قیمت کل\n",
      "4                   طبقه\n",
      "5             تعداد اتاق\n",
      "6               کل طبقات\n",
      "7     تعداد واحد در طبقه\n",
      "8               سال ساخت\n",
      "9                 موقعیت\n",
      "10              نوع ساخت\n",
      "11               نوع سند\n",
      "Name: Label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5eb3b03a-c2a8-48d6-bc9f-b78800b74300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract data from a single URL\n",
    "def extract_data(url, expected_labels):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    labels = [\n",
    "        \"کد آگهی\", \"منطقه\", \"محله\", \"متراژ\", \"قیمت کل\", \"طبقه\", \"تعداد اتاق\", \n",
    "        \"کل طبقات\", \"تعداد واحد در طبقه\", \"موقعیت\", \"نوع ساخت\", \"سال ساخت\", \"نوع سند\", \"زمان تحویل\"\n",
    "    ]\n",
    "    \n",
    "    label_elements = soup.find_all(class_=\"label-infmlk\")\n",
    "    text_elements = soup.find_all(class_=\"text-infmlk\")\n",
    "    \n",
    "    data = {label: \"\" for label in expected_labels}  # Initialize with empty strings\n",
    "    \n",
    "    for i in range(len(label_elements)):\n",
    "        label_text = label_elements[i].find('div').get_text(strip=True)\n",
    "        if label_text in labels:\n",
    "            text = text_elements[i].find('div').get_text(strip=True)\n",
    "            data[label_text] = text\n",
    "    \n",
    "    return pd.DataFrame([data])\n",
    "\n",
    "# List to hold all DataFrames\n",
    "dfs = pd.read_csv('combined_property_info.csv')\n",
    "\n",
    "# List of URLs to scrape\n",
    "def make_url(given_code):\n",
    "    if 10000 < given_code < 100000:\n",
    "        url = 'https://www.melketabriz.com/p/' + str(given_code)\n",
    "        df = extract_data(url, expected_labels)\n",
    "        dfs.append(df)\n",
    "        return dfs\n",
    "    else:\n",
    "        print('invalid code')\n",
    "        return None\n",
    "\n",
    "'''\n",
    "urls = [\n",
    "  'https://www.melketabriz.com/p/25923', \n",
    "    'https://www.melketabriz.com/p/31208',\n",
    "    # Add more URLs as needed\n",
    "]\n",
    "'''\n",
    "\n",
    "# Expected labels (columns)\n",
    "expected_labels = [\n",
    "    \"کد آگهی\", \"منطقه\", \"محله\", \"متراژ\", \"قیمت کل\", \"طبقه\", \"تعداد اتاق\", \n",
    "    \"کل طبقات\", \"تعداد واحد در طبقه\", \"موقعیت\", \"نوع ساخت\", \"سال ساخت\", \"نوع سند\", \"زمان تحویل\"\n",
    "]\n",
    "\n",
    "\n",
    "'''\n",
    "# Loop through URLs and extract data\n",
    "for url in urls:\n",
    "    df = extract_data(url, expected_labels)\n",
    "    dfs.append(df)\n",
    "'''\n",
    "\n",
    "def save_to_exel( ):\n",
    "    \n",
    "    # Concatenate all DataFrames, filling missing values with empty strings\n",
    "    combined_df = pd.concat(dfs, ignore_index=True )#.fillna('')\n",
    "    \n",
    "    # Save the combined DataFrame to a CSV file with UTF-8 encoding\n",
    "    combined_df.to_csv('combined_property_info.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # Print the combined DataFrame to verify\n",
    "    print(combined_df)\n",
    "    return 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb694d8e-b559-4a7d-a20b-b3687383b47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid code\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(make_url(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d3e872d-ea32-4965-b22b-0fa53f35f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_csv('combined_property_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3572943b-213b-4b85-ab66-20aeed731cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>کد آگهی</th>\n",
       "      <th>منطقه</th>\n",
       "      <th>محله</th>\n",
       "      <th>متراژ</th>\n",
       "      <th>قیمت کل</th>\n",
       "      <th>طبقه</th>\n",
       "      <th>تعداد اتاق</th>\n",
       "      <th>کل طبقات</th>\n",
       "      <th>تعداد واحد در طبقه</th>\n",
       "      <th>موقعیت</th>\n",
       "      <th>نوع ساخت</th>\n",
       "      <th>سال ساخت</th>\n",
       "      <th>نوع سند</th>\n",
       "      <th>زمان تحویل</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25923</td>\n",
       "      <td>کوی فیروز</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "      <td>۵٬۹۵۰٬۰۰۰٬۰۰۰تومان</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>جنوبی</td>\n",
       "      <td>شخصی ساز</td>\n",
       "      <td>1401</td>\n",
       "      <td>شش دانگ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31208</td>\n",
       "      <td>ولیعصر جنوبی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210</td>\n",
       "      <td>۹٬۴۰۰٬۰۰۰٬۰۰۰تومان</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>جنوبی</td>\n",
       "      <td>شخصی ساز</td>\n",
       "      <td>1402</td>\n",
       "      <td>در دست اقدام</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   کد آگهی         منطقه  محله  متراژ             قیمت کل  طبقه  تعداد اتاق  \\\n",
       "0    25923     کوی فیروز   NaN    175  ۵٬۹۵۰٬۰۰۰٬۰۰۰تومان     2           3   \n",
       "1    31208  ولیعصر جنوبی   NaN    210  ۹٬۴۰۰٬۰۰۰٬۰۰۰تومان     6           3   \n",
       "\n",
       "   کل طبقات  تعداد واحد در طبقه موقعیت  نوع ساخت  سال ساخت       نوع سند  \\\n",
       "0         6                   1  جنوبی  شخصی ساز      1401       شش دانگ   \n",
       "1         6                   1  جنوبی  شخصی ساز      1402  در دست اقدام   \n",
       "\n",
       "   زمان تحویل  \n",
       "0         NaN  \n",
       "1         NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c093d-2ed4-4b14-ad41-44ea9d097a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
